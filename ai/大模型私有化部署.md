> 此处以ChatGlm-6B开源大模型为例，部署前提是已经安装了python和pytorch
> pip3 install torch torchvision torchaudio --index-url https:/
/download.pytorch.org/whl/cu118

- 使用 git clone 对应的代码
```shell
git clone https://github.com/THUDM/ChatGLM-6B.git
```

- 安装依赖
```shell
cd ChatGLM-6B
pip install -r requirements.txt
```

- 下载模型
> 代码在执行时默认自动下载模型。如果没有使用魔法，你需要手动下载模型。在 清华大学云盘 下载模型，假设下载到 \chatglm-6b-models

- 大模型使用
```python
from transformers import AutoTokenizer, AutoModel
tokenizer = AutoTokenizer.from_pretrained(r"\chatglm-6b-models", trust_remote_code=True)
model = AutoModel.from_pretrained(r"\chatglm-6b-models", trust_remote_code=True).half().cuda()
model = model.eval()
response, history = model.chat(tokenizer, "你好", history=[])
print(response)
```