# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  jdbc{
     type => "order"
	 #The path to our download jdbc driver
	 jdbc_connection_string => "jdbc:mysql://xx.xx.xx.xx:3306/test?useConfigs=maxPerformance&characterEncoding=utf8"
	 jdbc_driver_library => "/logstash/driver/mysql-connector-java-5.1.46.jar"
	 jdbc_driver_class => "com.mysql.jdbc.driver"
	 
	 #The user we wish to execute our statement as
	 jdbc_user => "root"
	 jdbc_password => "root"
	 
	 #last_run_metadata_path => "./logstash_last_run_display"
	 
	 #every 5 minutes execute
	 #schedule => "*/5 * * * *"
	 schedule => "* * * * *"
	 #if clean_run set to true, sql_last_value is set to 19700101
	 clean_run => true 
	 last_run_metadata_path => "./last_run/logstash_jdbc_last_run"
	 #out query
	 #parameters => {"name" => "长沙大东家"}
	 #statement => "select * from sys_user where name = :name"
	 #statement => "select * from ydstore where createdTs > :sql_last_value"
	 statement => "select * from order where createdTs > :sql_last_value"
	 use_column_value => true
	 tracking_column => "update_date"
	 
	 jdbc_paging_enabled => "true"
	 jdbc_page_size => "1000"
	 
	 jdbc_default_timezone =>"Asia/Shanghai"
  }
}

filter {
  ruby {
    code => "event.set('id',event.get('pk'))"
  }
}

output {
  if[type]=="order" {
      stdout { codec => rubydebug }
	  elasticsearch {
			hosts => ["http://localhost:9200"]
			index => "%{type}"
			document_id => "%{id}"
			doc_as_upsert => true
			#user => "elastic"
			#password => "changeme"
			action => "update"
			manage_template=>true
			template_name=>"order"
			template_overwrite => true
			template => "/logstash/template/template-6.7.json"
	  }
  }
}
